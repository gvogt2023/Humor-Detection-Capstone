{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Workbook for Universal Sentence Encoder."
      ],
      "metadata": {
        "id": "q6WNyHj6_RVn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ai5HJhpxsJao",
        "outputId": "21106552-17a1-471f-c75c-09ffd82de339"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  humor\n",
            "0  Joe biden rules out 2020 bid: 'guys, i'm not r...  False\n",
            "1  Watch: darvish gave hitter whiplash with slow ...  False\n",
            "2  What do you call a turtle without its shell? d...   True\n",
            "3      5 reasons the 2016 election feels so personal  False\n",
            "4  Pasco police shot mexican migrant from behind,...  False\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV data into a DataFrame\n",
        "jokes_df = pd.read_csv('jokes_dataset.csv')\n",
        "\n",
        "# print the first 5 rows of the DataFrame\n",
        "print(jokes_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z_WkU3Wu8cK",
        "outputId": "cc510300-7083-4a4c-dc03-f76d568bf71e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import re\n",
        "\n",
        "# Download the stopwords corpus\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Define a function to preprocess the jokes\n",
        "def preprocess_jokes(jokes_df):\n",
        "    # Remove stopwords and punctuation\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    jokes_df['clean_joke'] = jokes_df['text'].apply(lambda x: ' '.join([word.lower() for word in x.split() if (word.lower() not in stop_words) and (word.lower() not in string.punctuation)]))\n",
        "    return jokes_df\n",
        "\n",
        "# Define a function to remove punctuation\n",
        "def remove_punctuation(text):\n",
        "    # Define the regular expression pattern to match any punctuation character\n",
        "    pattern = r'[^\\w\\s]'\n",
        "\n",
        "    # Use the sub() function to replace any matches with an empty string\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "    return cleaned_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v72LrvPIt_MA"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Preprocess the jokes\n",
        "preprocess_jokes(jokes_df)\n",
        "\n",
        "# Apply the remove_punctuation function to the Clean_joke column\n",
        "jokes_df['clean_joke'] = jokes_df['clean_joke'].apply(remove_punctuation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElWIFpnc5I12"
      },
      "outputs": [],
      "source": [
        "\n",
        "humorous_jokes_df = jokes_df[jokes_df['humor'] == True]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Universal Sentence Encoder:"
      ],
      "metadata": {
        "id": "bC2-xTCJAw8S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JxneDC9wWbQ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Load the model from TensorFlow Hub\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"\n",
        "model = hub.load(module_url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAdoL4p4yNZ6"
      },
      "outputs": [],
      "source": [
        "# Define batch size\n",
        "BATCH_SIZE = 1000\n",
        "\n",
        "# Initialize empty list to store encoded joke vectors\n",
        "joke_vectors_list = []\n",
        "\n",
        "# Encode jokes in batches\n",
        "for i in range(0, len(humorous_jokes_df), BATCH_SIZE):\n",
        "    # Get a batch of jokes\n",
        "    batch_jokes = humorous_jokes_df[\"clean_joke\"][i:i+BATCH_SIZE]\n",
        "    \n",
        "    # Encode the batch of jokes into vectors\n",
        "    batch_vectors = model(batch_jokes).numpy()\n",
        "    \n",
        "    # Append the batch of vectors to the list\n",
        "    joke_vectors_list.append(batch_vectors)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrudaAK_0jqa",
        "outputId": "a8fc1830-d6e7-427f-be72-3613e7b33615"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100000, 512)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "    \n",
        "# Concatenate the list of vectors into a single numpy array\n",
        "joke_vectors_array = np.concatenate(joke_vectors_list)\n",
        "\n",
        "# Print the shape of the joke vectors array\n",
        "print(joke_vectors_array.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBU0YNNeBqqC",
        "outputId": "a7057eaa-e85f-4975-a843-f99617191dfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.10272926 -0.01983313 -0.00284022 ... -0.00134287 -0.0245461\n",
            "   0.02391309]\n",
            " [ 0.00263279  0.08414213  0.02961861 ...  0.04268469  0.07342681\n",
            "   0.04781407]\n",
            " [ 0.02592236 -0.01635438 -0.02989341 ... -0.01631698 -0.07111952\n",
            "   0.03338585]\n",
            " ...\n",
            " [ 0.04659941 -0.0460685  -0.00383115 ...  0.03140274  0.04096763\n",
            "   0.05693741]\n",
            " [ 0.06997935 -0.06368115 -0.0437464  ... -0.07381413  0.01135412\n",
            "  -0.00506185]\n",
            " [ 0.01967495 -0.00077027  0.06616988 ... -0.01556989  0.04132042\n",
            "   0.03782702]]\n"
          ]
        }
      ],
      "source": [
        "print(joke_vectors_array[:10])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Need to save the joke_vectors array for later use with streamlit app."
      ],
      "metadata": {
        "id": "gUnoQrYIBOpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the array as an npy file\n",
        "np.save(\"joke_vectors.npy\", joke_vectors_array)"
      ],
      "metadata": {
        "id": "viviokZM-ZDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2WQBRRwBuiC",
        "outputId": "6b42dcde-ba95-463c-e878-60f9f5fa0e86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100000, 1000)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "batch_size = 1000\n",
        "\n",
        "similarity_matrix = None\n",
        "\n",
        "# Compute the pairwise cosine similarity between all joke vectors in batches\n",
        "for i in range(0, len(joke_vectors_array), batch_size):\n",
        "    batch_vectors = joke_vectors_array[i:i+batch_size]\n",
        "    if len(batch_vectors) < batch_size:  # pad the last batch if necessary\n",
        "        num_padding_rows = batch_size - len(batch_vectors)\n",
        "        padding_vectors = np.zeros((num_padding_rows, joke_vectors_array.shape[1]))\n",
        "        batch_vectors = np.concatenate([batch_vectors, padding_vectors], axis=0)\n",
        "    if similarity_matrix is None:\n",
        "        similarity_matrix = cosine_similarity(batch_vectors)\n",
        "    else:\n",
        "        similarity_matrix = np.concatenate(\n",
        "            [similarity_matrix, cosine_similarity(batch_vectors)], axis=0)\n",
        "\n",
        "# Print the shape of the similarity matrix\n",
        "print(similarity_matrix.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Need to save the similarity_matrix array for later use with streamlit app."
      ],
      "metadata": {
        "id": "VWc1GqmdBWhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  # Save the array as an npy file\n",
        "np.save(\"simalarity_matrix.npy\", similarity_matrix)"
      ],
      "metadata": {
        "id": "MkcWZGL5-WQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QF3juMudPbCb"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "# Load the Universal Sentence Encoder model from TensorFlow Hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "js_Jq0lMCoLZ",
        "outputId": "02748242-0419-457b-b7bc-47f4249108ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/My Drive/Jokes-Capstone'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A21bhSz_GwVj",
        "outputId": "5dd44417-e006-41e5-92c6-93b1ebcadb75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Jokes-Capstone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.copy('/content/joke_vectors.npy', '/content/drive/MyDrive/Jokes-Capstone/joke_vectors.npy')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "VAG39yE4HygL",
        "outputId": "037a4152-f4c0-4ee1-ee9b-5120b4305835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Jokes-Capstone/joke_vectors.npy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.copy('/content/simalarity_matrix.npy', '/content/drive/MyDrive/Jokes-Capstone/simalarity_matrix.npy')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ewWoPfsxIIgE",
        "outputId": "9223c4cd-1ed0-4d46-96d1-f000a2c237d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Jokes-Capstone/simalarity_matrix.npy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRYes61VCfZp",
        "outputId": "fec4d38f-4242-48cb-8df4-6fd311efe00c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a sentence: Dr. Seuss cat in the hat\n"
          ]
        }
      ],
      "source": [
        "# Given a user's input, encode it into a vector representation using the same Universal Sentence Encoder model.\n",
        "user_input = input(\"Enter a sentence: \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "589IP62ESwI6"
      },
      "outputs": [],
      "source": [
        "user_input_vector = embed([user_input])[0].numpy()\n",
        "similarity_scores = cosine_similarity(user_input_vector.reshape(1, -1), joke_vectors_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKYHLvOHLd2G",
        "outputId": "396ff785-cb6c-4a4f-ba2f-4353b028135d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How many jokes would you like to see? 5\n"
          ]
        }
      ],
      "source": [
        "# Get the number of jokes to recommend from the user\n",
        "num_jokes = int(input(\"How many jokes would you like to see? \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtQdK37aWrxx"
      },
      "outputs": [],
      "source": [
        "# Get the top-n jokes with the highest similarity scores\n",
        "top_indices = np.argsort(similarity_scores, axis=1)[:, ::-1][:, :num_jokes].ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvL8KrZXXUzq"
      },
      "outputs": [],
      "source": [
        "top_jokes = [humorous_jokes_df.iloc[i] for i in top_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cTWOw_b4r-k",
        "outputId": "5cd268e5-4e3f-4d8b-b364-f125b759050f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[text          What did dr. seuss call the book he wrote abou...\n",
              " humor                                                      True\n",
              " clean_joke          dr seuss call book wrote star wars cat atat\n",
              " Name: 151470, dtype: object,\n",
              " text          What was schrodinger's favorite childhood book...\n",
              " humor                                                      True\n",
              " clean_joke    schrodingers favorite childhood book cat box d...\n",
              " Name: 42771, dtype: object,\n",
              " text          What is dr. seuss' favorite play? green eggs a...\n",
              " humor                                                      True\n",
              " clean_joke             dr seuss favorite play green eggs hamlet\n",
              " Name: 87722, dtype: object,\n",
              " text          Did you read dr seuss as a kid because green e...\n",
              " humor                                                      True\n",
              " clean_joke                    read dr seuss kid green eggs damn\n",
              " Name: 150734, dtype: object,\n",
              " text          What do you call a magician in a dr. seuss boo...\n",
              " humor                                                      True\n",
              " clean_joke                  call magician dr seuss book whodini\n",
              " Name: 57004, dtype: object]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "top_jokes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ot6TR0BXxVB",
        "outputId": "e291cd93-881f-42a5-dd41-4a00fadddf37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 jokes:\n",
            "1. What did dr. seuss call the book he wrote about star wars? the cat in the at-at\n",
            "2. What was schrodinger's favorite childhood book? the cat in the box by dr. seuss\n",
            "3. What is dr. seuss' favorite play? green eggs and hamlet\n",
            "4. Did you read dr seuss as a kid because green eggs and damn\n",
            "5. What do you call a magician in a dr. seuss book? who-dini\n"
          ]
        }
      ],
      "source": [
        "# Print the top-n jokes\n",
        "print(f\"Top {num_jokes} jokes:\")\n",
        "for i, joke in enumerate(top_jokes):\n",
        "    print(f\"{i+1}. {joke.text}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (learn-env)",
      "language": "python",
      "name": "learn-env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}